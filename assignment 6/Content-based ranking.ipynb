{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymorphy2 scipy numpy pandas\n",
    "!pip install -U pymorphy2-dicts-ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.sparse import dok_matrix\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем и токенизируем весь корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Майкл Джордан признан лучшим игроком в истории...</td>\n",
       "      <td>Двукратный олимпийский чемпион, американец Май...</td>\n",
       "      <td>http://www.vesti.ru/doc.html?id=3264755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ОАК сократила сроки импортозамещения компонент...</td>\n",
       "      <td>\"Объединенная авиастроительная корпорация\" (ОА...</td>\n",
       "      <td>http://www.vesti.ru/doc.html?id=3264736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Китай выступил против продажи Францией оружия ...</td>\n",
       "      <td>Китай предупредил Францию, чтобы та не продава...</td>\n",
       "      <td>http://www.vesti.ru/doc.html?id=3264743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В Чувашии на оснащение \"Точек  роста\" выделят ...</td>\n",
       "      <td>В Чувашии на базе 42 школ создадут Центры обра...</td>\n",
       "      <td>http://www.vesti.ru/doc.html?id=3264744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Следовавший из Петербурга в Уфу самолет \"Росси...</td>\n",
       "      <td>Вылетевший из Санкт-Петербурга в Уфу самолет а...</td>\n",
       "      <td>http://www.vesti.ru/doc.html?id=3264746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Майкл Джордан признан лучшим игроком в истории...   \n",
       "1  ОАК сократила сроки импортозамещения компонент...   \n",
       "2  Китай выступил против продажи Францией оружия ...   \n",
       "3  В Чувашии на оснащение \"Точек  роста\" выделят ...   \n",
       "4  Следовавший из Петербурга в Уфу самолет \"Росси...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Двукратный олимпийский чемпион, американец Май...   \n",
       "1  \"Объединенная авиастроительная корпорация\" (ОА...   \n",
       "2  Китай предупредил Францию, чтобы та не продава...   \n",
       "3  В Чувашии на базе 42 школ создадут Центры обра...   \n",
       "4  Вылетевший из Санкт-Петербурга в Уфу самолет а...   \n",
       "\n",
       "                                       url  \n",
       "0  http://www.vesti.ru/doc.html?id=3264755  \n",
       "1  http://www.vesti.ru/doc.html?id=3264736  \n",
       "2  http://www.vesti.ru/doc.html?id=3264743  \n",
       "3  http://www.vesti.ru/doc.html?id=3264744  \n",
       "4  http://www.vesti.ru/doc.html?id=3264746  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('news.csv.gzip', sep=';', compression='gzip')\n",
    "data = data[['title', 'content', 'url']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "\n",
    "# Парсим и выбираем нормальную форму с максимальной вероятностью\n",
    "def build_normal_form(word):\n",
    "    parse = morph.parse(word)\n",
    "    normal_form = None\n",
    "    last_max_score = 0\n",
    "    for p in parse:\n",
    "        if p.score > last_max_score:\n",
    "            normal_form = p.normal_form\n",
    "            last_max_score = p.score\n",
    "    return normal_form\n",
    "\n",
    "\n",
    "# Функция токенизации текста\n",
    "def tokenize_text(text):\n",
    "    content = list()\n",
    "    all_words = [word.lower() for word in re.findall(r\"[A-za-zА-Яа-я]\\w*\", text) if word]\n",
    "    for word in all_words:        \n",
    "        normal_form = build_normal_form(word)\n",
    "        if normal_form is not None:\n",
    "            content.append(normal_form)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['tokenized_content'] = data['content'].apply(tokenize_text)\n",
    "corpus = list(data['content'])\n",
    "tokenized_corpus = list(data['tokenized_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим инвертированный индекс и задаем функцию бинарного поиска по нему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция построения словаря из корпуса\n",
    "def build_index_dictionary(tokenized_texts, max_word_freq=0.8):\n",
    "    invert_index = collections.defaultdict(list)\n",
    "        \n",
    "    for index_doc, text in enumerate(tokenized_texts):\n",
    "        unique_text_words = set(text)\n",
    "        for word in unique_text_words:\n",
    "            invert_index[word].append(index_doc)\n",
    "                \n",
    "    max_word_freq = len(tokenized_texts) * max_word_freq\n",
    "#    invert_index = {word: docs for word, docs in invert_index.items() if len(docs) < max_word_freq}    \n",
    "    return invert_index\n",
    "\n",
    "\n",
    "# Фукнкция поиска в инвертированном индексе\n",
    "def search(user_normal_input, invert_index):\n",
    "    docs = set()\n",
    "    word_in = 0\n",
    "    for word in user_normal_input:\n",
    "        if word in invert_index:\n",
    "            word_in += 1\n",
    "            new_docs = set(invert_index[word])\n",
    "            docs = docs & new_docs if docs else  new_docs\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 842 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50917"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "invert_index = build_index_dictionary(tokenized_corpus)\n",
    "len(invert_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим словарик и векторизуем корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(tokenized_texts, max_doc_freq=0.8, min_count=5, pad_word=None):\n",
    "    word_counts = collections.defaultdict(int)\n",
    "    doc_n = len(tokenized_texts)\n",
    "    # посчитать количество документов, в которых употребляется каждое слово\n",
    "    # а также общее количество документов\n",
    "    for txt in tokenized_texts:\n",
    "        unique_text_tokens = set(txt)\n",
    "        for token in unique_text_tokens:\n",
    "            word_counts[token] += 1\n",
    "\n",
    "    # убрать слишком редкие и слишком частые слова\n",
    "    #word_counts = {word: cnt for word, cnt in word_counts.items()\n",
    "    #               if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
    "\n",
    "    # отсортировать слова по убыванию частоты\n",
    "    sorted_word_counts = sorted(word_counts.items(),\n",
    "                                reverse=True,\n",
    "                                key=lambda pair: pair[1])\n",
    "\n",
    "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
    "    if pad_word is not None:\n",
    "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
    "\n",
    "    # нумеруем слова\n",
    "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "\n",
    "    return word2id\n",
    "\n",
    "\n",
    "def vectorize_texts_bin(tokenized_texts, vocabulary):\n",
    "    # Каждая строка соответствует документу\n",
    "    result = dok_matrix((len(tokenized_texts), len(vocabulary)), dtype='float32')\n",
    "    for text_i, text in enumerate(tokenized_texts):\n",
    "        for word in text:\n",
    "            if word in vocabulary:\n",
    "                result[text_i, vocabulary[word]] += 1\n",
    "    \n",
    "    # получаем бинарные вектора \"встречается или нет\"\n",
    "    result = (result > 0).astype('float32') \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vocabulary = build_vocabulary(tokenized_corpus)\n",
    "vectorized_documents = vectorize_texts_bin(tokenized_corpus, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задаем функции подсчета метрик и нахождения релевантных документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cosine_from_sparse = lambda x, y: cosine(x.toarray()[0], y.toarray()[0])\n",
    "\n",
    "\n",
    "def get_BM25(Q, D, tokenized_corpus, invert_index, k=2, b = 0.75):\n",
    "    all_docs = len(tokenized_corpus)\n",
    "    avgdl = np.average([len(item) for item in tokenized_corpus])\n",
    "\n",
    "    score = 0\n",
    "    # Считаем кол-во повторов слов и общую длину предложения\n",
    "    D_count = Counter(D)\n",
    "    doc_len = len(D)\n",
    "\n",
    "    for word in Q: #doc:\n",
    "        word = build_normal_form(word)\n",
    "        count_D_with_word = len(invert_index.get(word, []))\n",
    "        if count_D_with_word:\n",
    "            fqD = D_count[word]\n",
    "\n",
    "            idf = np.log(all_docs / count_D_with_word)\n",
    "            numerator = fqD * (k + 1)\n",
    "            denominator = fqD + k * (1 - b + b * (doc_len / avgdl) )\n",
    "            score += idf * (numerator / denominator)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N_relevant_docs(user_input, vectorized_documents, all_documents, vocabulary, N=0, score_type='VSM'):\n",
    "    user_normal_input = [build_normal_form(u_i) for u_i in user_input.split(' ')]\n",
    "    # для нахождения косинусного расстояния пересчитываем ввод в вектор\n",
    "    if score_type=='VSM': \n",
    "        input_vector = vectorize_texts_bin(user_normal_input, vocabulary)\n",
    "    \n",
    "    # Находим подходящие документы\n",
    "    relevant_docs = search(user_normal_input, invert_index)\n",
    "\n",
    "    ranged_docs = list()\n",
    "    for doc_index in relevant_docs:\n",
    "        if score_type=='VSM':  \n",
    "            score = get_cosine_from_sparse(input_vector, vectorized_documents[doc_index])\n",
    "        else:\n",
    "            score = get_BM25(user_normal_input, all_documents[doc_index], tokenized_corpus, invert_index)\n",
    "        \n",
    "        ranged_docs.append((score, doc_index))\n",
    "    \n",
    "    # Сортируем по убыванию\n",
    "    ranged_docs = sorted(ranged_docs, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Если задано ограничение, то отрезать лишние результаты\n",
    "    if N and len(ranged_docs) > N:\n",
    "        ranged_docs = ranged_docs[:N]\n",
    "    \n",
    "    result = list()\n",
    "    for r_doc in ranged_docs:\n",
    "        doc_index = r_doc[1]\n",
    "        doc = all_documents[doc_index]\n",
    "        result.append(doc)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для вывода результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для экономии места ограничим вывод текста 100 словами\n",
    "def print_relevant(user_input, score_type, N=2, max_words=100):    \n",
    "    for text in get_N_relevant_docs(user_input, vectorized_documents, corpus, vocabulary, N, score_type=score_type):\n",
    "        all_words = text.split(' ')\n",
    "        if len(all_words) > max_words:\n",
    "            text = f\"{' '.join(all_words[:max_words])}...\"\n",
    "        print(text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестируем на произвольных запросах VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чемпионат Польши по футболу будет возобновлен 31 мая. Матчи будут проходить без зрителей. Как сообщает \"Спорт-Экспресс\", президент Футбольного союза Польши Збигнев Бонек считает, что уже 10 мая футболисты могут приступить к тренировкам. 31 мая могут начаться матчи чемпионата страны, которые пройдут без зрителей. В польской Экстракласе сыграно 26 туров из 30. На первом месте идет варшавская \"Легия\". \n",
      "\n",
      "Полузащитник футбольного клуба \"Монако\" Александр Головин, который до 11 мая должен был вернуться в стан монегасков, принял решение на ближайшее время остаться в России. Как сообщает \"Спорт-экспресс\", 23-летний футболист планирует приехать в княжество в июне, когда \"Монако\" проведет первый сбор. Напомним, что чемпионат Франции по футболу был прекращен досрочно из-за угрозы распространения коронавирусной инфекции. Чемпионом страны стал \"Пари Сен-Жермен\", а клуб Головина завершил турнир на девятой строчке. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = 'спорт Футбол'\n",
    "print_relevant(user_input, score_type='VSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В Челябинской области карантин объявлен в одном из храмов. Выяснилось, что у четырех служительниц обнаружен коронавирус. Об этом сообщает ГТРК \"Южный Урал\". Как уточняется на странице храма в соцсети, приход временно закрыт. Храм Покрова расположен в Каслинском районе в селе Булзи. Сейчас все заболевшие находятся в челябинской больнице. Контактировавшие с ними отправлены домой на карантин, им сделаны анализы на наличие коронавируса. Кроме того, всех прихожан, посещавших храм с Пасхи, попросили соблюдать режим самоизоляции. Как известно, COVID-19 недавно был обнаружен у трех священников Свято-Симеоновского собора в Челябинске. С 29 апреля в связи с эпидемией коронавируса временно закрыты для посещения все храмы...\n",
      "\n",
      "Российским властям удается держать развитие смертоносной эпидемии под контролем, а в этой исключительно трудной для всех ситуации еще и сохранять моральное лидерство. Делать это, однако, приходится в условиях, когда жесткая культурная критика идет и справа, и слева. Но интересно, что и тот, и другой фланги совпадают в одном: не нужны столь строгие ограничительные меры со стороны государства, не нужен и столь строгий государственный контроль за перемещением граждан. Мол, загоняют нас в \"цифровое рабство\" под предлогом угрозы, опасность которой завышается, а правду все равно не говорят. Ярче многих в пасхальной проповеди выступил основатель Среднеуральского женского монастыря схиигумен Екатеринбургской епархии Русской Православной...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Челябинск карантин'\n",
    "print_relevant(user_input, score_type='VSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аналитик Fitch Solutions заявил, что США и несколько европейских стран по-прежнему ежедневно сообщают о тысячах новых случаев инфицированием коронавируса, поэтому остаются вопросы о том, смогут ли они безопасно ослабить ограничения, направленные на обуздание пандемии, пишет CNBC. Эти ограничения, которые включают запреты на поездки и временное закрытие предприятий и школ, привели к тому, что значительная часть мировой экономической активности зашла в тупик. Отмечая признаки того, что распространение вируса начало замедляться, многие правительства стремятся перезапустить экономическую активность. Но Седрик Чехаб из Fitch Solutions сказал, что опыт Китая по отмене этих ограничений показал, что может возникнуть новая волна инфекций. \"Китай поэтапно открывает свою...\n",
      "\n",
      "Северокорейский лидер Ким Чен Ын, скорее всего, действительно имеет серьезные проблемы со здоровьем. Как передает CNN, об этом заявил Тхэ Ён Хо — бывший посол КНДР в Лондоне, сбежавший в Южную Корею в 2016 году.Еще одна версия о состоянии главы государства появилась на фоне его исчезновения из публичного поля. По мнению Тхэ Ён Хо, отсутствие Ким Чен Ына на мероприятиях по случаю дня рождения Ким Ир Сена для населения страны выглядит ненормально. «Я не совсем уверен, действительно ли он перенес какую-то операцию или что-то еще. Ясно одно — он не может самостоятельно встать или нормально ходить», — поделился экс-дипломат.При этом...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Трамп заявил Корея'\n",
    "print_relevant(user_input, score_type='VSM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестируем на произвольных запросах BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бывший защитник «Спартака», трехкратный чемпион России Эдуард Мор не согласен с мнением, что футболисты получают высокие зарплаты в ущерб работникам бюджетной сферы — учителей и врачей. Об этом он написал в своем Twitter.По воспоминаниям Мора, в Калмыкии люди ненавидели игроков местного «Уралана», получавших в разы больше бюджетников. Однако, подчеркивает экс-футболист, после того, как команды не стало, проблемы для бюджетников так и не были решены.«Может, раскулачить пару полковников? Тогда денег хватит не только на футбол в Московской области, но и на всю медицину, весь спорт и образование в стране» — написал Мор. Он добавил, что также считает зарплаты футболистов завышенными, но...\n",
      "\n",
      "Какие эмодзи используются в сообщениях о спортсменах, выяснила соцсеть Одноклассники. ОК, как социальная сеть, куда люди приходят обмениваться эмоциями, проанализировала посты и комментарии своих пользователей за последний год. Самыми популярными эмодзи, которые используются при упоминании спортсменов, стали подмигивание, грусть и победный смайл с высунутым языком. В топе замечены и тематические смайлы – тенисная ракетка и баскетбольная корзина с мячом. Пьедестал почета по оличеству упоминаний с эмодзи вошли теннисистка Мария Шарапова, трехкратный призер Олимпиад пловчиха Юлия Ефимова и капитан сборной России по футболу, нападающий петербургского \"Зенита\" Артем Дзюба. О Маше Шараповой чаще всего пишут, используя эмодзи досады, теннисного мяча и полицейской...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = 'спорт Футбол'\n",
    "print_relevant(user_input, score_type='BM25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отдел полиции «Южный» в городе Миасс Челябинской области закрыли на карантин из-за коронавируса. Об этом сообщает региональное управление МВД.Все сотрудники подразделения находятся на режиме изоляции, чтобы не допустить распространения опасной инфекции. Их наблюдают специалисты медико-санитарной части МВД. В здании отдела полиции проведена дезинфекция помещений. Содействие в охране общественного порядка оказывают полицейские ближайших территориальных органов внутренних дел и Главного управления МВД России по Челябинской области.Карантин был введен в связи с заражением двух сотрудников отдела «Южный», один из которых участковый, сообщает Znak.com. Издание напоминает, что ранее на изоляцию в полном составе уходила прокуратура Металлургического района Челябинска из-за одной заразившейся сотрудницы. Через две...\n",
      "\n",
      "Российским властям удается держать развитие смертоносной эпидемии под контролем, а в этой исключительно трудной для всех ситуации еще и сохранять моральное лидерство. Делать это, однако, приходится в условиях, когда жесткая культурная критика идет и справа, и слева. Но интересно, что и тот, и другой фланги совпадают в одном: не нужны столь строгие ограничительные меры со стороны государства, не нужен и столь строгий государственный контроль за перемещением граждан. Мол, загоняют нас в \"цифровое рабство\" под предлогом угрозы, опасность которой завышается, а правду все равно не говорят. Ярче многих в пасхальной проповеди выступил основатель Среднеуральского женского монастыря схиигумен Екатеринбургской епархии Русской Православной...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Челябинск карантин'\n",
    "print_relevant(user_input, score_type='BM25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аналитик Fitch Solutions заявил, что США и несколько европейских стран по-прежнему ежедневно сообщают о тысячах новых случаев инфицированием коронавируса, поэтому остаются вопросы о том, смогут ли они безопасно ослабить ограничения, направленные на обуздание пандемии, пишет CNBC. Эти ограничения, которые включают запреты на поездки и временное закрытие предприятий и школ, привели к тому, что значительная часть мировой экономической активности зашла в тупик. Отмечая признаки того, что распространение вируса начало замедляться, многие правительства стремятся перезапустить экономическую активность. Но Седрик Чехаб из Fitch Solutions сказал, что опыт Китая по отмене этих ограничений показал, что может возникнуть новая волна инфекций. \"Китай поэтапно открывает свою...\n",
      "\n",
      "Власти США считают необычным отсутствие лидера КНДР Ким Чен Ына, который пропал более чем на две недели и не принимает участие в публичных событиях. Соединенные Штаты готовятся к любому развитию ситуации, заявил госсекретарь страны Майкл Помпео в эфире радиостанции IHeart. Его слова приводит ТАСС.Помпео отметил, что США не получали сведений о появлении северокорейского лидера на публике в течение немногим более двух недель. «Это не является неслыханным, но это необычно, — сказал американский госсекретарь, — Мы продолжаем внимательно следить за этим. Мы работаем над тем, чтобы при любой ситуации в итоге мы были подготовлены».Представитель США отметил, что, как и говорил президент...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Трамп заявил Корея'\n",
    "print_relevant(user_input, score_type='BM25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разметим релевантность статей и посчитаем метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним выдачу топ-30 по 5-ти запросам\n",
    "def news_to_csv(user_input, score_type, N=30, max_words=100):\n",
    "    relevant_markup = list()\n",
    "    for u_i in user_input:\n",
    "        relevant_docs = get_N_relevant_docs(u_i, vectorized_documents, corpus, vocabulary, N, score_type=score_type)\n",
    "        for index, text in enumerate(relevant_docs):\n",
    "            mark = {'position':  index, 'news': text, 'query': u_i, 'mark': ''}\n",
    "            relevant_markup.append(mark)\n",
    "\n",
    "    mark_frame = pandas.DataFrame(relevant_markup)\n",
    "    mark_frame.to_csv(f'mark_frame_{score_type}.csv', sep=';', index=False)\n",
    "    \n",
    "\n",
    "user_input = ['Трамп Китай коронавирус', 'Госдума приняла законопроект', \n",
    "          'Олимпиада Токио', 'маски в Санкт-Петербурге', 'Павел Дуров объявил']\n",
    "\n",
    "news_to_csv(user_input, score_type='VSM', N=30)\n",
    "news_to_csv(user_input, score_type='BM25', N=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# После ручной разметки считаем результат и сохраним по каждому запросу поток отметок\n",
    "\n",
    "markup_to_VSM = pandas.read_csv('mark_frame_VSM.csv', sep=',')\n",
    "markup_to_BM25 = pandas.read_csv('mark_frame_BM25.csv', sep=',')\n",
    "\n",
    "markup_vsm = list()\n",
    "markup_bm25 = list()\n",
    "\n",
    "for query in markup_to_BM25['query'].unique():\n",
    "    markup_vsm.append(list(markup_to_BM25[markup_to_BM25['query'] == query]['mark']))\n",
    "    markup_bm25.append(list(markup_to_VSM[markup_to_VSM['query'] == query]['mark']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика MAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь и далее все формулы взяты из статьи:\n",
    "https://habr.com/ru/company/econtenta/blog/303458/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision at K\n",
    "APaK = lambda marks: (1/len(marks)) * sum([marks[index-1]* sum(marks[:index]) / index for index in range(1, len(marks)+1)])\n",
    "\n",
    "# Mean average precision at K\n",
    "MAPaK = lambda answers, N: (1/len(answers)) * sum([APaK(marks[:N]) for marks in answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VSM scores:\n",
      "MAP@1: 0.6000000000000001\n",
      "MAP@5: 0.5593333333333333\n",
      "MAP@10: 0.5717142857142857\n",
      "MAP@15: 0.5473412698412699\n"
     ]
    }
   ],
   "source": [
    "print('VSM scores:')\n",
    "print(f\"MAP@1: {MAPaK(markup_vsm, 1)}\")\n",
    "print(f\"MAP@5: {MAPaK(markup_vsm, 5)}\")\n",
    "print(f\"MAP@10: {MAPaK(markup_vsm, 10)}\")\n",
    "print(f\"MAP@15: {MAPaK(markup_vsm, 15)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 scores:\n",
      "MAP@1: 0.4\n",
      "MAP@5: 0.4546666666666667\n",
      "MAP@10: 0.43434126984126986\n",
      "MAP@15: 0.4328689273689274\n"
     ]
    }
   ],
   "source": [
    "print('BM25 scores:')\n",
    "print(f\"MAP@1: {MAPaK(markup_bm25, 1)}\")\n",
    "print(f\"MAP@5: {MAPaK(markup_bm25, 5)}\")\n",
    "print(f\"MAP@10: {MAPaK(markup_bm25, 10)}\")\n",
    "print(f\"MAP@15: {MAPaK(markup_bm25, 15)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрика NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discounted Cumulative Gain at K\n",
    "DCGaK = lambda marks: sum([marks[index-1] / np.log2(1 + index) for index in range(1, len(marks)+1)])\n",
    "\n",
    "# Ideal discounted Cumulative Gain at K\n",
    "IDCGaK = lambda marks: sum([1 / np.log2(1 + index) for index in range(1, len(marks)+1)])\n",
    "\n",
    "# Normalized Discounted Cumulative Gain at K\n",
    "NDCG = lambda answers, N: sum([DCGaK(marks[:N]) / IDCGaK(marks[:N]) for marks in answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VSM scores:\n",
      "NDCG@1: 3.0\n",
      "NDCG@5: 3.1695801026368082\n",
      "NDCG@10: 3.319729868438214\n",
      "NDCG@15: 3.2076345266685147\n"
     ]
    }
   ],
   "source": [
    "print('VSM scores:')\n",
    "print(f\"NDCG@1: {NDCG(markup_vsm, 1)}\")\n",
    "print(f\"NDCG@5: {NDCG(markup_vsm, 5)}\")\n",
    "print(f\"NDCG@10: {NDCG(markup_vsm, 10)}\")\n",
    "print(f\"NDCG@15: {NDCG(markup_vsm, 15)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 scores:\n",
      "NDCG@1: 0.4\n",
      "NDCG@5: 0.4546666666666667\n",
      "NDCG@10: 0.43434126984126986\n",
      "NDCG@15: 0.4328689273689274\n"
     ]
    }
   ],
   "source": [
    "print('BM25 scores:')\n",
    "print(f\"NDCG@1: {MAPaK(markup_bm25, 1)}\")\n",
    "print(f\"NDCG@5: {MAPaK(markup_bm25, 5)}\")\n",
    "print(f\"NDCG@10: {MAPaK(markup_bm25, 10)}\")\n",
    "print(f\"NDCG@15: {MAPaK(markup_bm25, 15)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
